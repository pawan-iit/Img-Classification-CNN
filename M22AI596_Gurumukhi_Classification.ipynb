{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WkKCMtbRi9Dcm7YqRJBFxnXY8y839bsm",
      "authorship_tag": "ABX9TyMCyxdjzgTi1u/BKFhhtilQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawan-iit/Img-Classification-CNN/blob/main/M22AI596_Gurumukhi_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hX7i5azZv-f-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "from keras.layers import Dense, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your image folders\n",
        "train_path = '/content/drive/MyDrive/ML_Assignment3/Q2/train'\n",
        "val_path = '/content/drive/MyDrive/ML_Assignment3/val'\n"
      ],
      "metadata": {
        "id": "Jhj5AqcYwH5M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the folder containing the 'train' folder\n",
        "data_dir = train_path\n",
        "# Set the image size\n",
        "img_size = (32, 32)\n",
        "# Create empty lists for the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "# Loop over each folder from '0' to '9'\n",
        "for label in range(10):\n",
        "    folder_path = os.path.join(data_dir, 'train', str(label))\n",
        "    # Loop over each image in the folder\n",
        "    for file in os.listdir(folder_path):\n",
        "      file_path = os.path.join(folder_path, file)\n",
        "      if file_path.endswith(('.tiff','.bmp')):\n",
        "       # Load the image and resize it to the desired size\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, img_size)\n",
        "        # Append the image and label to the lists\n",
        "      images.append(img)\n",
        "      labels.append(label)\n",
        "# Convert the lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "# Save the arrays in NumPy format\n",
        "np.save('x_train.npy', images)\n",
        "np.save('y_train.npy', labels)\n"
      ],
      "metadata": {
        "id": "SDyn3AjYwL7g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the folder containing the 'val' folder\n",
        "data_dir_val = val_path\n",
        "# Set the image size\n",
        "img_size_val = (32, 32)\n",
        "# Create empty lists for the images and labels\n",
        "images_val = []\n",
        "labels_val = []\n",
        "# Loop over each folder from '0' to '9'\n",
        "for label in range(10):\n",
        "    folder_path = os.path.join(data_dir_val, 'val', str(label))\n",
        "    # Loop over each image in the folder\n",
        "    for file in os.listdir(folder_path):\n",
        "      file_path = os.path.join(folder_path, file)\n",
        "      if file_path.endswith(('.tiff','.bmp')):\n",
        "      # Load the image and resize it to the desired size\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, img_size_val)\n",
        "      # Append the image and label to the lists\n",
        "      images_val.append(img)\n",
        "      labels_val.append(label)\n",
        "# Convert the lists to NumPy arrays\n",
        "images_val = np.array(images_val)\n",
        "labels_val = np.array(labels_val)\n",
        "# Save the arrays in NumPy format\n",
        "np.save('x_test.npy', images_val)\n",
        "np.save('y_test.npy', labels_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IyPFlNqbyZq5",
        "outputId": "aa96ee5d-0aa1-4c71-c384-15e24facca4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9356cd8a7cf4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Loop over each image in the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tiff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.bmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML_Assignment3/val/val/0'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "x_train = np.load('x_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "y_test = np.load('y_test.npy')\n"
      ],
      "metadata": {
        "id": "4ir2unZ7ywvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the images are loaded correctly\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "x_train[0].shape\n",
        "x_train[0]\n",
        "plt.matshow(x_train[0])\n",
        "plt.matshow(x_train[999])\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "y_train\n",
        "y_test\n",
        "plt.matshow(x_test[150])\n"
      ],
      "metadata": {
        "id": "CN8nI7jLyzMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# activation function is sigmoid\n",
        "model = keras.Sequential([\n",
        "keras.layers.Flatten(),\n",
        "keras.layers.Dense(10, input_shape=(1024,),activation = 'sigmoid')\n",
        "])\n",
        "# compile the nn\n",
        "model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy']\n",
        ")\n",
        "# train the model\n",
        "# some 10 iterations done here\n",
        "model.fit(x_train, y_train,epochs= 10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "2-mD4Wdby0AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation : we see a better accuracy from the 2nd iteration\n",
        "# now scale and try to check the accuracy, divide dataset by 255\n",
        "x_train_scaled = x_train/255\n",
        "x_test_scaled = x_test/255\n",
        "model.fit(x_train_scaled, y_train,epochs= 10, validation_data=(x_test_scaled, y_test))\n"
      ],
      "metadata": {
        "id": "yTL7kVIKzGEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation : we got better result for all iterations on scaling the training dataset\n"
      ],
      "metadata": {
        "id": "Rea2RPdOzIij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate test dataset\n",
        "model.evaluate(x_test_scaled,y_test)\n"
      ],
      "metadata": {
        "id": "UWTIoSXGzK_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation : result almost same as the training dataset,\n"
      ],
      "metadata": {
        "id": "jPqdYDCWzQFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict 1st image\n",
        "plt.matshow(x_test[0])\n",
        "y_predicted = model.predict(x_test_scaled)\n",
        "y_predicted[0]\n",
        "# this showing the 10 results for the input '0', we need to look for the value which is max\n",
        "print('Predicted Value is ',np.argmax(y_predicted[0]))\n",
        "# test some more values\n",
        "plt.matshow(x_test[88])\n",
        "print('Predicted Value is ',np.argmax(y_predicted[88]))\n",
        "plt.matshow(x_test[177])\n",
        "print('Predicted Value is ',np.argmax(y_predicted[177]))\n"
      ],
      "metadata": {
        "id": "KOaaOH5GzSh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some predictions may not be not right\n",
        "# build confusion matrix to see how our prediction looks like\n",
        "# convert to concrete values\n",
        "y_predicted_labels=[np.argmax(i) for i in y_predicted]\n",
        "print(y_predicted_labels, len(y_predicted_labels))\n",
        "conf_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
        "conf_mat\n"
      ],
      "metadata": {
        "id": "iQxGb_12zW9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "plt.figure(figsize = (10,10))\n",
        "sn.heatmap(conf_mat,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n"
      ],
      "metadata": {
        "id": "FKZMXWQazZnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we can see there are some errors\n",
        "# we need to modify our nn, we add some layers in the above model and different activation function\n"
      ],
      "metadata": {
        "id": "zVIjF6y1zZgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in 1st Dense layer,the input is 32 x 32 = 1024 neurons, which will give 10 output(numbers from 0 to 9)\n",
        "# 2nd Dense layer,the input is 10 neurons from above layers output\n",
        "# we can add more layers for accuracy\n",
        "model2 = keras.Sequential([\n",
        "keras.layers.Flatten(),\n",
        "keras.layers.Dense(1024,input_shape=(1024,), activation='relu'),\n",
        "keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "# compile the nn\n",
        "model2.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy']\n",
        ")\n",
        "# train the model\n",
        "# some 10 iterations done here\n",
        "history = model2.fit(x_train_scaled, y_train,epochs= 10, validation_data=(x_test_scaled, y_test))\n"
      ],
      "metadata": {
        "id": "YJ-bLeG1zdkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation : due to multiple layers the compiling will take more time to execute\n",
        "# we also got amazing accuracy than earlier\n",
        "# evaluate test dataset on modified model\n",
        "model2.evaluate(x_test_scaled,y_test)\n"
      ],
      "metadata": {
        "id": "3CHttxWzzml5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redo the confusion matrix\n",
        "# build confusion matrix to see how our prediction looks like\n",
        "# convert to concrete values\n",
        "y_predicted = model2.predict(x_test_scaled)\n",
        "y_predicted[0]\n",
        "y_predicted_labels=[np.argmax(i) for i in y_predicted]\n",
        "print(y_predicted_labels, len(y_predicted_labels))\n",
        "conf_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted_labels)\n",
        "conf_mat\n"
      ],
      "metadata": {
        "id": "Wd3bmZqSzpHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sn.heatmap(conf_mat,annot=True,fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n"
      ],
      "metadata": {
        "id": "TAIQePVZzrjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observatoin : we see in the updated model, there are less number of errors,\n",
        "# whatever is not in diagonal is a error\n"
      ],
      "metadata": {
        "id": "RO_HlNa9zuUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pIwB0s4yzvKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9oN4mN1zxxh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}